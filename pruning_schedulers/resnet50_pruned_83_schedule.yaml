# This schedule demonstrates high-rate element-wise pruning (83.37% sparsity) of Resnet 50.

# ************************************************************
# Accuracy Performance
# ************************************************************
# +----------------------+------------------+----------------+
# | Accuracy Metric      | Pruned Model     | Base Model     |
# +----------------------+------------------+----------------+
# | Top1                 | 75.766           | 76.15          |
# | Top5                 | 92.92            | 92.87          |
# +----------------------+------------------+----------------+

# ************************************************************
# Distiller Command Line
# ************************************************************
# Training      : python compress_classifier.py -a=resnet50 --pretrained -p=100 PATH_TO_IMAGENET_DATA -j=8 -b=32 --epochs=120 --lr=0.001 --compress=PATH_TO_THIS_FILE
# Evaluation    : python compress_classifier.py -a resnet50 --resume PATH_TO_CHEKCPOINT PATH_TO_IMAGENET_VAL_DATA --evaluate
# Quantization  : python compress_classifier.py -a resnet50 --resume PATH_TO_CHEKCPOINT PATH_TO_IMAGENET_VAL_DATA --evaluate --quantize-eval --qe-mode asym_u

# ************************************************************
# Best epoch (117)
# ************************************************************

# ************************************************************
# Sparsity Profile
# ************************************************************
# There are three different levels of pruning: (a) layer1.x pruned by 50% (b) layer2.x pruned by 66% and (c) layer 3.x and layer 4.x pruned by 85%. The last Linear layer is
# pruned to 80% sparsity.
#

# Parameters:
# +----+-------------------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# |    | Name                                | Shape              |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
# |----+-------------------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
# |  0 | module.conv1.weight                 | (64, 3, 7, 7)      |          9408 |           9408 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10824 | -0.00036 |    0.06728 |
# |  1 | module.layer1.0.conv1.weight        | (64, 64, 1, 1)     |          4096 |           2048 |    0.00000 |    0.00000 |  1.56250 | 50.00000 |  7.81250 |   50.00000 | 0.05526 | -0.00316 |    0.02695 |
# |  2 | module.layer1.0.conv2.weight        | (64, 64, 3, 3)     |         36864 |          18432 |    0.00000 |    0.00000 |  7.81250 | 14.30664 |  6.25000 |   50.00000 | 0.02400 |  0.00056 |    0.01216 |
# |  3 | module.layer1.0.conv3.weight        | (256, 64, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 |  4.68750 | 50.00000 | 10.15625 |   50.00000 | 0.02948 |  0.00046 |    0.01567 |
# |  4 | module.layer1.0.downsample.0.weight | (256, 64, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 |  1.56250 | 50.00000 |  9.76562 |   50.00000 | 0.04325 | -0.00248 |    0.02149 |
# |  5 | module.layer1.1.conv1.weight        | (64, 256, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 | 10.54688 | 50.00000 |  6.25000 |   50.00000 | 0.02476 |  0.00108 |    0.01393 |
# |  6 | module.layer1.1.conv2.weight        | (64, 64, 3, 3)     |         36864 |          18432 |    0.00000 |    0.00000 |  6.25000 |  7.32422 |  0.00000 |   50.00000 | 0.02305 |  0.00009 |    0.01263 |
# |  7 | module.layer1.1.conv3.weight        | (256, 64, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 |  0.00000 | 50.00000 |  2.73438 |   50.00000 | 0.02699 |  0.00007 |    0.01446 |
# |  8 | module.layer1.2.conv1.weight        | (64, 256, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 |  3.12500 | 50.00000 |  0.00000 |   50.00000 | 0.02423 | -0.00019 |    0.01400 |
# |  9 | module.layer1.2.conv2.weight        | (64, 64, 3, 3)     |         36864 |          18432 |    0.00000 |    0.00000 |  0.00000 |  1.63574 |  0.00000 |   50.00000 | 0.02487 | -0.00047 |    0.01463 |
# | 10 | module.layer1.2.conv3.weight        | (256, 64, 1, 1)    |         16384 |           8192 |    0.00000 |    0.00000 |  0.00000 | 50.00000 |  0.00000 |   50.00000 | 0.02591 | -0.00165 |    0.01349 |
# | 11 | module.layer2.0.conv1.weight        | (128, 256, 1, 1)   |         32768 |          11142 |    0.00000 |    0.00000 |  0.00000 | 65.99731 |  0.00000 |   65.99731 | 0.02511 | -0.00102 |    0.01231 |
# | 12 | module.layer2.0.conv2.weight        | (128, 128, 3, 3)   |        147456 |          50136 |    0.00000 |    0.00000 |  0.00000 | 11.35254 |  0.00000 |   65.99935 | 0.01577 | -0.00021 |    0.00772 |
# | 13 | module.layer2.0.conv3.weight        | (512, 128, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  0.00000 | 65.99884 | 12.10938 |   65.99884 | 0.02101 |  0.00016 |    0.00945 |
# | 14 | module.layer2.0.downsample.0.weight | (512, 256, 1, 1)   |        131072 |          44565 |    0.00000 |    0.00000 |  0.00000 | 65.99960 | 12.30469 |   65.99960 | 0.01593 | -0.00026 |    0.00680 |
# | 15 | module.layer2.1.conv1.weight        | (128, 512, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 | 12.30469 | 65.99884 |  0.00000 |   65.99884 | 0.01337 |  0.00005 |    0.00593 |
# | 16 | module.layer2.1.conv2.weight        | (128, 128, 3, 3)   |        147456 |          50136 |    0.00000 |    0.00000 |  0.00000 | 15.31372 |  0.00000 |   65.99935 | 0.01554 |  0.00013 |    0.00714 |
# | 17 | module.layer2.1.conv3.weight        | (512, 128, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  0.00000 | 65.99884 |  1.17188 |   65.99884 | 0.01772 | -0.00088 |    0.00765 |
# | 18 | module.layer2.2.conv1.weight        | (128, 512, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  1.36719 | 65.99884 |  0.00000 |   65.99884 | 0.01746 | -0.00054 |    0.00817 |
# | 19 | module.layer2.2.conv2.weight        | (128, 128, 3, 3)   |        147456 |          50136 |    0.00000 |    0.00000 |  0.00000 |  8.97827 |  0.00000 |   65.99935 | 0.01614 | -0.00014 |    0.00759 |
# | 20 | module.layer2.2.conv3.weight        | (512, 128, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  0.00000 | 65.99884 |  0.00000 |   65.99884 | 0.01967 | -0.00029 |    0.00927 |
# | 21 | module.layer2.3.conv1.weight        | (128, 512, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  0.00000 | 65.99884 |  0.00000 |   65.99884 | 0.01813 | -0.00056 |    0.00880 |
# | 22 | module.layer2.3.conv2.weight        | (128, 128, 3, 3)   |        147456 |          50136 |    0.00000 |    0.00000 |  0.00000 |  7.06787 |  0.00000 |   65.99935 | 0.01641 | -0.00037 |    0.00808 |
# | 23 | module.layer2.3.conv3.weight        | (512, 128, 1, 1)   |         65536 |          22283 |    0.00000 |    0.00000 |  0.00000 | 65.99884 |  0.00000 |   65.99884 | 0.01860 | -0.00043 |    0.00863 |
# | 24 | module.layer3.0.conv1.weight        | (256, 512, 1, 1)   |        131072 |          19661 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.00000 |   84.99985 | 0.01851 | -0.00038 |    0.00637 |
# | 25 | module.layer3.0.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 49.81995 |  0.00000 |   84.99993 | 0.01046 | -0.00011 |    0.00349 |
# | 26 | module.layer3.0.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  4.58984 |   84.99985 | 0.01469 |  0.00004 |    0.00499 |
# | 27 | module.layer3.0.downsample.0.weight | (1024, 512, 1, 1)  |        524288 |          78644 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  4.00391 |   84.99985 | 0.00993 | -0.00003 |    0.00318 |
# | 28 | module.layer3.1.conv1.weight        | (256, 1024, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  4.78516 | 84.99985 |  0.00000 |   84.99985 | 0.01108 | -0.00009 |    0.00362 |
# | 29 | module.layer3.1.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 42.23175 |  0.00000 |   84.99993 | 0.01018 | -0.00008 |    0.00337 |
# | 30 | module.layer3.1.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  1.07422 |   84.99985 | 0.01333 | -0.00068 |    0.00445 |
# | 31 | module.layer3.2.conv1.weight        | (256, 1024, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.58594 | 84.99985 |  0.00000 |   84.99985 | 0.01078 | -0.00015 |    0.00348 |
# | 32 | module.layer3.2.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 35.23102 |  0.00000 |   84.99993 | 0.00987 | -0.00027 |    0.00329 |
# | 33 | module.layer3.2.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.39062 |   84.99985 | 0.01226 | -0.00026 |    0.00411 |
# | 34 | module.layer3.3.conv1.weight        | (256, 1024, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.19531 | 84.99985 |  0.00000 |   84.99985 | 0.01169 | -0.00013 |    0.00386 |
# | 35 | module.layer3.3.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 34.40857 |  0.00000 |   84.99993 | 0.00986 | -0.00025 |    0.00332 |
# | 36 | module.layer3.3.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.68359 |   84.99985 | 0.01200 | -0.00046 |    0.00405 |
# | 37 | module.layer3.4.conv1.weight        | (256, 1024, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.09766 | 84.99985 |  0.00000 |   84.99985 | 0.01200 | -0.00027 |    0.00401 |
# | 38 | module.layer3.4.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 35.62622 |  0.00000 |   84.99993 | 0.00984 | -0.00035 |    0.00333 |
# | 39 | module.layer3.4.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.58594 |   84.99985 | 0.01215 | -0.00066 |    0.00411 |
# | 40 | module.layer3.5.conv1.weight        | (256, 1024, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.00000 |   84.99985 | 0.01276 | -0.00020 |    0.00435 |
# | 41 | module.layer3.5.conv2.weight        | (256, 256, 3, 3)   |        589824 |          88474 |    0.00000 |    0.00000 |  0.00000 | 37.80670 |  0.00000 |   84.99993 | 0.01007 | -0.00035 |    0.00344 |
# | 42 | module.layer3.5.conv3.weight        | (1024, 256, 1, 1)  |        262144 |          39322 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  1.17188 |   84.99985 | 0.01310 | -0.00103 |    0.00454 |
# | 43 | module.layer4.0.conv1.weight        | (512, 1024, 1, 1)  |        524288 |          78644 |    0.00000 |    0.00000 |  0.00000 | 84.99985 |  0.00000 |   84.99985 | 0.01457 | -0.00022 |    0.00514 |
# | 44 | module.layer4.0.conv2.weight        | (512, 512, 3, 3)   |       2359296 |         353895 |    0.00000 |    0.00000 |  0.00000 | 49.08981 |  0.00000 |   84.99997 | 0.00794 | -0.00012 |    0.00274 |
# | 45 | module.layer4.0.conv3.weight        | (2048, 512, 1, 1)  |       1048576 |         157287 |    0.00000 |    0.00000 |  0.00000 | 84.99994 |  0.00000 |   84.99994 | 0.01094 | -0.00012 |    0.00380 |
# | 46 | module.layer4.0.downsample.0.weight | (2048, 1024, 1, 1) |       2097152 |         314573 |    0.00000 |    0.00000 |  0.00000 | 84.99999 |  0.00000 |   84.99999 | 0.00738 | -0.00013 |    0.00242 |
# | 47 | module.layer4.1.conv1.weight        | (512, 2048, 1, 1)  |       1048576 |         157287 |    0.00000 |    0.00000 |  0.00000 | 84.99994 |  0.00000 |   84.99994 | 0.01139 | -0.00017 |    0.00392 |
# | 48 | module.layer4.1.conv2.weight        | (512, 512, 3, 3)   |       2359296 |         353895 |    0.00000 |    0.00000 |  0.00000 | 44.53850 |  0.00000 |   84.99997 | 0.00845 | -0.00031 |    0.00295 |
# | 49 | module.layer4.1.conv3.weight        | (2048, 512, 1, 1)  |       1048576 |         157287 |    0.00000 |    0.00000 |  0.00000 | 84.99994 |  0.00000 |   84.99994 | 0.01139 |  0.00012 |    0.00399 |
# | 50 | module.layer4.2.conv1.weight        | (512, 2048, 1, 1)  |       1048576 |         157287 |    0.00000 |    0.00000 |  0.00000 | 84.99994 |  0.00000 |   84.99994 | 0.01321 | -0.00006 |    0.00464 |
# | 51 | module.layer4.2.conv2.weight        | (512, 512, 3, 3)   |       2359296 |         353895 |    0.00000 |    0.00000 |  0.00000 | 59.29794 |  0.00000 |   84.99997 | 0.00703 | -0.00017 |    0.00256 |
# | 52 | module.layer4.2.conv3.weight        | (2048, 512, 1, 1)  |       1048576 |         157287 |    0.00000 |    0.00000 |  0.00000 | 84.99994 |  0.04883 |   84.99994 | 0.00932 |  0.00025 |    0.00326 |
# | 53 | module.fc.weight                    | (1000, 2048)       |       2048000 |         409600 |    0.00000 |    0.14648 |  0.00000 |  0.00000 |  0.00000 |   80.00000 | 0.03173 |  0.00393 |    0.01231 |
# | 54 | Total sparsity:                     | -                  |      25502912 |        4240764 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   83.37145 | 0.00000 |  0.00000 |    0.00000 |
# +----+-------------------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# Total sparsity: 83.37

# Ideal Number of MACS: 1.143 Billion

version: 1

pruners:
  fc_pruner:
    class: AutomatedGradualPruner
    initial_sparsity : 0.05
    final_sparsity: 0.80
    weights: module.fc.weight

  conv_pruner:
    class: AutomatedGradualPruner
    initial_sparsity : 0.05
    final_sparsity: 0.5
    weights: [
    #module.conv1.weight,
    module.layer1.0.conv1.weight,
    module.layer1.0.conv2.weight,
    module.layer1.0.conv3.weight,
    module.layer1.0.downsample.0.weight,
    module.layer1.1.conv1.weight,
    module.layer1.1.conv2.weight,
    module.layer1.1.conv3.weight,
    module.layer1.2.conv1.weight,
    module.layer1.2.conv2.weight,
    module.layer1.2.conv3.weight]

  conv_pruner1:
    class: AutomatedGradualPruner
    initial_sparsity : 0.05
    final_sparsity: 0.66
    weights: [
    #module.conv1.weight,
    module.layer2.0.conv1.weight,
    module.layer2.0.conv2.weight,
    module.layer2.0.conv3.weight,
    module.layer2.0.downsample.0.weight,
    module.layer2.1.conv1.weight,
    module.layer2.1.conv2.weight,
    module.layer2.1.conv3.weight,
    module.layer2.2.conv1.weight,
    module.layer2.2.conv2.weight,
    module.layer2.2.conv3.weight,
    module.layer2.3.conv1.weight,
    module.layer2.3.conv2.weight,
    module.layer2.3.conv3.weight]

  conv_pruner2:
    class: AutomatedGradualPruner
    initial_sparsity : 0.05
    final_sparsity: 0.85
    weights: [
    module.layer3.0.conv1.weight,
    module.layer3.0.conv2.weight,
    module.layer3.0.conv3.weight,
    module.layer3.0.downsample.0.weight,
    module.layer3.1.conv1.weight,
    module.layer3.1.conv2.weight,
    module.layer3.1.conv3.weight,
    module.layer3.2.conv1.weight,
    module.layer3.2.conv2.weight,
    module.layer3.2.conv3.weight,
    module.layer3.3.conv1.weight,
    module.layer3.3.conv2.weight,
    module.layer3.3.conv3.weight,
    module.layer3.4.conv1.weight,
    module.layer3.4.conv2.weight,
    module.layer3.4.conv3.weight,
    module.layer3.5.conv1.weight,
    module.layer3.5.conv2.weight,
    module.layer3.5.conv3.weight,
    module.layer4.0.conv1.weight,
    module.layer4.0.conv2.weight,
    module.layer4.0.conv3.weight,
    module.layer4.0.downsample.0.weight,
    module.layer4.1.conv1.weight,
    module.layer4.1.conv2.weight,
    module.layer4.1.conv3.weight,
    module.layer4.2.conv1.weight,
    module.layer4.2.conv2.weight,
    module.layer4.2.conv3.weight]

lr_schedulers:
   pruning_lr:
     class: ExponentialLR
     gamma: 0.95


policies:

  - pruner:
      instance_name : conv_pruner
    starting_epoch: 0
    ending_epoch: 35
    frequency: 1
  - pruner:
      instance_name : conv_pruner1
    starting_epoch: 0
    ending_epoch: 35
    frequency: 1

  - pruner:
      instance_name : conv_pruner2
    starting_epoch: 0
    ending_epoch: 35
    frequency: 1


  - pruner:
      instance_name : fc_pruner
    starting_epoch: 1
    ending_epoch: 35
    frequency: 1

  - lr_scheduler:
      instance_name: pruning_lr
    starting_epoch: 40
    ending_epoch: 100
    frequency: 1
